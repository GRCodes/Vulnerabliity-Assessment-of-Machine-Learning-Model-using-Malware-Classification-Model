#importing the Libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd


#importing the dataset for both good and bad queries from the repository
goodDataset = pd.read_csv('badq.csv')
goodDataset = goodDataset[0: 500]
badDataset = pd.read_excel('Good.xlsx')
badDataset = badDataset[0: 500]

#Combining the datasets to create a dataset which would be used to train and test sets
totalDataset = pd.concat([goodDataset, badDataset], ignore_index=True)


# Cleaning the Queries for the machine model
import re
import nltk

corpus = []
for i in range(0, 1000):
    cleanDataset = re.sub('[^a-zA-Z]', ' ', totalDataset['Sql_Queries'][i])
    cleanDataset = cleanDataset.lower()
    cleanDataset = cleanDataset.split()
    cleanDataset = ''.join(cleanDataset)
    corpus.append(cleanDataset)

#Creating Bag of words
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 500)
X = cv.fit_transform(corpus).toarray()
y = totalDataset.iloc[:, 1].values

# Splitting the dataset into the Training set and Test set
from sklearn.cross_validation import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)


# Fitting Naive Bayes to the Training set
from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)

# Predicting the Test set results
y_pred = classifier.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
